{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPVvl81rJIAxdEQp1p0wRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedshafik98/hello-world/blob/master/resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qlXlknvRODg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "7083654d-9ad8-4857-edc6-f0b9e25dee6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Aai90lRZxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "576bf315-09ae-4c3c-ccef-402ed9262d56"
      },
      "source": [
        "\n",
        "#impoet libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "%matplotlib inline\n",
        "\n",
        "#I have stored all the images of cats and dogs in the folder dogs-vs-cats folder. We read the cat and dog files. We have 25003 images each of cats and dogs\n",
        "\n",
        "\n",
        "files = glob.glob('C:\\\\Users\\\\Elalamia\\\\Desktop\\\\dogs-vs-cats*') \n",
        " \n",
        "cat_files = [fn for fn in files if 'cat' in fn] \n",
        "dog_files = [fn for fn in files if 'dog' in fn] \n",
        "len(cat_files), len(dog_files)\n",
        "\n",
        "#I am training on a smaller set of data so reducing the size of my training, test and validation data set. This step is not required if you want to train on all the images\n",
        "#Train data set will have 1500 images each of cats and dogs, Test data set will have 500 images each of cats and dogs and Validation data set will also have 500 images each of cats and dogs\n",
        "\n",
        "cat_train = np.random.choice(cat_files, size=1500, replace=False) \n",
        "dog_train = np.random.choice(dog_files, size=1500, replace=False) \n",
        "cat_files = list(set(cat_files) — set(cat_train)) \n",
        "dog_files = list(set(dog_files) — set(dog_train)) \n",
        " \n",
        "cat_val = np.random.choice(cat_files, size=500, replace=False) \n",
        "dog_val = np.random.choice(dog_files, size=500, replace=False) \n",
        "cat_files = list(set(cat_files) — set(cat_val)) \n",
        "dog_files = list(set(dog_files) — set(dog_val)) \n",
        " \n",
        "cat_test = np.random.choice(cat_files, size=500, replace=False) \n",
        "dog_test = np.random.choice(dog_files, size=500, replace=False) \n",
        " \n",
        "print(‘Cat datasets:’, cat_train.shape, cat_val.shape, cat_test.shape) \n",
        "print(‘Dog datasets:’, dog_train.shape, dog_val.shape, dog_test.shape)\n",
        "\n",
        "\n",
        "#Loading the training and validation data set. The dimension of our image will be 300 by 300 pixel\n",
        "\n",
        "IMG_WIDTH=300\n",
        "IMG_HEIGHT=300\n",
        "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
        "train_files = glob.glob(‘E:\\\\Data\\\\Images\\\\dogs-vs-cats\\\\training_data\\\\*’)\n",
        "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
        "train_imgs = np.array(train_imgs)\n",
        "train_labels = [fn.split(‘\\\\’)[-1].split(‘.’)[0].strip() for fn in train_files]\n",
        "validation_files = glob.glob(‘E:\\\\Data\\\\Images\\\\dogs-vs-cats\\\\validation_data\\\\*’)\n",
        "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
        "validation_imgs = np.array(validation_imgs)\n",
        "validation_labels = [fn.split(‘\\\\’)[-1].split(‘.’)[0].strip() for fn in validation_files]\n",
        "print(‘Train dataset shape:’, train_imgs.shape, \n",
        " ‘\\tValidation dataset shape:’, validation_imgs.shape)\n",
        "\n",
        "\n",
        "##Each image is now of size 300 x 300 and has three channels for Red, Green, and Blue (RGB).\n",
        "#Pixel values for images are between 0 and 255. Deep Neural networks work well with smaller input values. Scaling each image with values between 0 and 1.\n",
        "\n",
        "train_imgs_scaled = train_imgs.astype(‘float32’) \n",
        "validation_imgs_scaled = validation_imgs.astype(‘float32’) \n",
        "train_imgs_scaled /= 255 \n",
        "validation_imgs_scaled /= 255 \n",
        " \n",
        "# visualize a sample image \n",
        "print(train_imgs[0].shape) \n",
        "array_to_img(train_imgs[0]\n",
        "             \n",
        "\n",
        "#Encoding text category labels of Cats and Dogs\n",
        "# encode text category labels \n",
        "from sklearn.preprocessing import LabelEncoder \n",
        " \n",
        "le = LabelEncoder() \n",
        "le.fit(train_labels) \n",
        "train_labels_enc = le.transform(train_labels) \n",
        "validation_labels_enc = le.transform(validation_labels) \n",
        " \n",
        "print(train_labels[1495:1505], train_labels_enc[1495:1505])\n",
        "\n",
        "\n",
        "#Applying Data Augmentation to images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        " width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        " horizontal_flip=True, fill_mode=’nearest’)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "####\n",
        "img_id = 2500\n",
        "cat_generator = train_datagen.flow(train_imgs[img_id:img_id+1], \n",
        " train_labels[img_id:img_id+1], \n",
        " batch_size=1) \n",
        "cat = [next(cat_generator) for i in range(0,5)] \n",
        "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
        "print(‘Labels:’, [item[1][0] for item in cat]) \n",
        "l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "img_id = 4001 \n",
        "dog_generator = train_datagen.flow(train_imgs[img_id:img_id+1], \n",
        " train_labels[img_id:img_id+1], \n",
        " batch_size=1) \n",
        "dog = [next(dog_generator) for i in range(0,5)] \n",
        "fig, ax = plt.subplots(1,5, figsize=(15, 6)) \n",
        "print(‘Labels:’, [item[1][0] for item in dog]) \n",
        "l = [ax[i].imshow(dog[i][0][0]) for i in range(0,5)]\n",
        "\n",
        "\n",
        "#We just apply image augmentation transformations only to our training set images and validation images\n",
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc,batch_size=30)\n",
        "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=30)\n",
        "\n",
        "#Transfer learning using Pre-trained model as Feature Extractor\n",
        "#“include_top=False”. We do this so that we can add our own fully connected layers on top of the ResNet50 model for our task-specific classification.\n",
        "\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "import keras\n",
        "restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
        "output = restnet.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "restnet = Model(restnet.input, output=output)\n",
        "for layer in restnet.layers:\n",
        "    layer.trainable = False\n",
        "restnet.summary()\n",
        "\n",
        "\n",
        "#We now create our model using Transfer Learning using Pre-trained ResNet50 by adding our own fully connected layer and the final classifier using sigmoid activation function.\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "model = Sequential()\n",
        "model.add(restnet)\n",
        "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#we now run the model\n",
        "history = model.fit_generator(train_generator, \n",
        "                              steps_per_epoch=100, \n",
        "                              epochs=100,\n",
        "                              validation_data=val_generator, \n",
        "                              validation_steps=50, \n",
        "                              verbose=1)\n",
        "#Saving the trained weights\n",
        "model.save(‘cats_dogs_tlearn_img_aug_cnn_restnet50.h5’)\n",
        "\n",
        "#unfreezing a few of the last convolution blocks while keeping the first early conv blocks frozen.\n",
        "restnet.trainable = True\n",
        "set_trainable = False\n",
        "for layer in restnet.layers:\n",
        "    if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in restnet.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\n",
        "\n",
        "\n",
        "#we now add our own fully connected layer and classifier on top of the ResNet50. We have already removed the last fully connected layer and the classifier layer from ResNet50\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "model_finetuned = Sequential()\n",
        "model_finetuned.add(restnet)\n",
        "model_finetuned.add(Dense(512, activation='relu', input_dim=input_shape))\n",
        "model_finetuned.add(Dropout(0.3))\n",
        "model_finetuned.add(Dense(512, activation='relu'))\n",
        "model_finetuned.add(Dropout(0.3))\n",
        "model_finetuned.add(Dense(1, activation='sigmoid'))\n",
        "model_finetuned.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['accuracy'])\n",
        "model_finetuned.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#We finally run the model\n",
        "history_1 = model_finetuned.fit_generator(train_generator, \n",
        "                                  steps_per_epoch=100, \n",
        "                                  epochs=2,\n",
        "                                  validation_data=val_generator, \n",
        "                                  validation_steps=100, \n",
        "                                  verbose=1)\n",
        "#saving the weights of the fine-tuned model\n",
        "model.save(‘cats_dogs_tlearn_finetune_img_aug_restnet50.h5’)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-95d87fd56ed4>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    cat_files = list(set(cat_files) — set(cat_train))\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    }
  ]
}